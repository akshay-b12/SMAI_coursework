{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1ycHiWk-L_C"
   },
   "source": [
    "# Q-4 Regression\n",
    "\n",
    "*   Akshay Bankar (2019201011)\n",
    "\n",
    "#### Household power consumption data - Time series forcasting :\n",
    "\n",
    "    A time series is a sequence of observations taken sequentially in time.\n",
    "Time series adds an explicit order dependence between observations: a time dimension.\n",
    "This additional dimension is both a constraint and a structure that provides a source of additional information.\n",
    "\n",
    "The household power consumption data is a multivariate series comprised of seven variables (besides the date and time); they are:\n",
    "\n",
    "    global_active_power: The total active power consumed by the household (kilowatts).\n",
    "    global_reactive_power: The total reactive power consumed by the household (kilowatts).\n",
    "    voltage: Average voltage (volts).\n",
    "    global_intensity: Average current intensity (amps).\n",
    "    sub_metering_1: Active energy for kitchen (watt-hours of active energy).\n",
    "    sub_metering_2: Active energy for laundry (watt-hours of active energy).\n",
    "    sub_metering_3: Active energy for climate control systems (watt-hours of active energy).\n",
    "\n",
    "\n",
    "\n",
    "*   In the given problem we are asked to perform regression over the dataset of global active power values. \n",
    "*   We are supposed to take the active power values in the past one hour and predict the next active power value\n",
    "\n",
    "**Hence it becomes a Univariate time series problem where dataset comprises of a single series of observations with a temporal ordering**\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKthlmWguyA6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iWNYQvIBFiP"
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "\n",
    "> Using read_csv() function of pandas to load the data and combine the first two columns into a single date-time column that can be used as an index.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "4Z4Rp_lYKAKK",
    "outputId": "9cd079d4-b3dc-4d38-b31d-5e3d33530a8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv('/content/drive/My Drive/household_power_consumption.txt', delimiter=';', infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "qI0c6tzIKs7W",
    "outputId": "0a8548f5-6c80-48e7-b644-d896cfd4b1b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Global_active_power  ... Sub_metering_3\n",
       "datetime                                 ...               \n",
       "2006-12-16 17:24:00               4.216  ...           17.0\n",
       "2006-12-16 17:25:00               5.360  ...           16.0\n",
       "2006-12-16 17:26:00               5.374  ...           17.0\n",
       "2006-12-16 17:27:00               5.388  ...           17.0\n",
       "2006-12-16 17:28:00               3.666  ...           17.0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LNpB56eqC2C-"
   },
   "source": [
    "\n",
    "\n",
    "> Fill missing values : mark all missing values indicated with a ‘?‘ character with a NaN value.\n",
    "\n",
    "> Using **forward filling** (Walk-Forward), we fill the missing values with the previous days' values as this is logical for a time series data that the pattern of values will be very close to values with previous timestamps.\n",
    "\n",
    "**Walk-Forward :** the actual data for that hour is made available to the model so that it can be used as the basis for making a prediction on the subsequent hour.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fGhZbQsBsXB0"
   },
   "outputs": [],
   "source": [
    "def fill_missing(values):\n",
    "\tone_day = 60 * 24\n",
    "\tfor row in range(values.shape[0]):\n",
    "\t\tfor col in range(values.shape[1]):\n",
    "\t\t\tif np.isnan(values[row, col]):\n",
    "\t\t\t\tvalues[row, col] = values[row - one_day, col]\n",
    " \n",
    "# mark all missing values\n",
    "dataframe.replace('?', np.nan , inplace=True)\n",
    "# make dataset numeric\n",
    "dataframe = dataframe.astype('float32')\n",
    "# fill missing\n",
    "fill_missing(dataframe.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PuEz1ao1EANs"
   },
   "source": [
    "\n",
    "\n",
    "> Extract the \"Global_active_power\" column from the data so that the dataset is a **Univariate** now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "UmGpmz4AKzJ9",
    "outputId": "ea3c3c30-60f8-4856-db68-19eb7c3f9750"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2006-12-16 17:24:00    4.216\n",
       "2006-12-16 17:25:00    5.360\n",
       "2006-12-16 17:26:00    5.374\n",
       "2006-12-16 17:27:00    5.388\n",
       "2006-12-16 17:28:00    3.666\n",
       "Name: Global_active_power, dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataframe['Global_active_power']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ORyXWtLVEfaL"
   },
   "source": [
    "#### Create data samples :\n",
    "\n",
    "> Divide the sequence into multiple input/output patterns called samples, where 60 observations corresponding to an hour are used as input and one time step is used as output for the one-step prediction that is being learned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ETuDBDFGNe47",
    "outputId": "fc3fd611-ea2d-4730-c041-1bde0ce059e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input-output samples : (2075199, 60)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_sequence(sequence, n_steps):\n",
    "\t  X, y = list(), list()\n",
    "\t  for i in range(len(sequence)):\n",
    "\t  \tend_ix = i + n_steps\n",
    "\t  \tif end_ix > len(sequence)-1:\n",
    "\t  \t\tbreak\n",
    "\t  \tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t  \tX.append(seq_x)\n",
    "\t  \ty.append(seq_y)\n",
    "\t  return np.array(X), np.array(y)\n",
    "\n",
    "steps = 60\n",
    "X, y = split_sequence(df.to_numpy(), n_steps=steps)\n",
    "print(\"Number of input-output samples :\",np.shape(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLVdSQVDFxPh"
   },
   "source": [
    "### Regression using MLP\n",
    "\n",
    "> Import keras libraries to be used to build MLP model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCAKH8ewTUSN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.backend import variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xECAevPNF8dT"
   },
   "source": [
    "\n",
    "\n",
    "> Define model with one, two and three hidden layer with RELU activation function and with loss function as mean-square-error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeVO0Y4rTwmQ"
   },
   "outputs": [],
   "source": [
    "##### Model with one hidden layer #####\n",
    "model_1layer = Sequential()\n",
    "model_1layer.add(Dense(100, activation='relu', input_dim=steps))\n",
    "model_1layer.add(Dense(1))\n",
    "model_1layer.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "##### Model with two hidden layers #####\n",
    "model_2layer = Sequential()\n",
    "model_2layer.add(Dense(100, activation='relu', input_dim=steps))\n",
    "model_2layer.add(Dense(100, activation='relu', input_dim=100))\n",
    "model_2layer.add(Dense(1))\n",
    "model_2layer.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "##### Model with three hidden layer #####\n",
    "model_3layer = Sequential()\n",
    "model_3layer.add(Dense(100, activation='relu', input_dim=steps))\n",
    "model_3layer.add(Dense(100, activation='relu', input_dim=100))\n",
    "model_3layer.add(Dense(100, activation='relu', input_dim=100))\n",
    "model_3layer.add(Dense(1))\n",
    "model_3layer.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnX9tyd-G226"
   },
   "source": [
    "\n",
    "\n",
    "> Fit the above three models defined with batch_sizev= 64 and 10 epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J-En9C9XIsbl",
    "outputId": "810ce0eb-e54c-4985-de2f-622b21c1c354"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8890036940>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1layer.fit(X_train, y_train, epochs=5, batch_size = 64, verbose=0)\n",
    "model_2layer.fit(X_train, y_train, epochs=5, batch_size = 64, verbose=0)\n",
    "model_3layer.fit(X_train, y_train, epochs=5, batch_size = 64, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oM6F_dNUJELD"
   },
   "source": [
    "\n",
    "\n",
    "> Predict on test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PO7SWGcU4uMP"
   },
   "outputs": [],
   "source": [
    "y_pred_1layer = model_1layer.predict(X_test, verbose=0)\n",
    "y_pred_2layer = model_2layer.predict(X_test, verbose=0)\n",
    "y_pred_3layer = model_3layer.predict(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zDAdCLsJJsM"
   },
   "source": [
    "\n",
    "\n",
    "> Calculate MSE and R2-score for the three models.\n",
    "\n",
    "> Observation : The model with two hidden layers performs well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "UPfW_4xE6Ycp",
    "outputId": "8660158d-ed4d-4157-d6b3-ab6f61a786c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with one layer: 0.07\n",
      "Variance score with one layer: 0.94\n",
      "Mean squared error with two layers: 0.07\n",
      "Variance score with two layers: 0.94\n",
      "Mean squared error with three layers: 0.07\n",
      "Variance score with three layers: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "print(\"Mean squared error with one layer: %.2f\" % mean_squared_error(y_test, y_pred_1layer))\n",
    "print('Variance score with one layer: %.2f' % r2_score(y_test, y_pred_1layer))\n",
    "\n",
    "print(\"Mean squared error with two layers: %.2f\" % mean_squared_error(y_test, y_pred_2layer))\n",
    "print('Variance score with two layers: %.2f' % r2_score(y_test, y_pred_2layer))\n",
    "\n",
    "print(\"Mean squared error with three layers: %.2f\" % mean_squared_error(y_test, y_pred_3layer))\n",
    "print('Variance score with three layers: %.2f' % r2_score(y_test, y_pred_3layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zsm_x679opqB"
   },
   "source": [
    "### Evaluation with different activation functions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U48pla02pTO4"
   },
   "outputs": [],
   "source": [
    "steps = 60\n",
    "##### Model with sigmoid activation function #####\n",
    "model_2layer_sig = Sequential()\n",
    "model_2layer_sig.add(Dense(100, activation='sigmoid', input_dim=steps))\n",
    "model_2layer_sig.add(Dense(100, activation='sigmoid', input_dim=100))\n",
    "model_2layer_sig.add(Dense(1))\n",
    "model_2layer_sig.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "##### Model with tanh activation function #####\n",
    "model_2layer_tanh = Sequential()\n",
    "model_2layer_tanh.add(Dense(100, activation='tanh', input_dim=steps))\n",
    "model_2layer_tanh.add(Dense(100, activation='tanh', input_dim=100))\n",
    "model_2layer_tanh.add(Dense(1))\n",
    "model_2layer_tanh.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "##### Model with linear activation function #####\n",
    "model_2layer_lin = Sequential()\n",
    "model_2layer_lin.add(Dense(100, activation='linear', input_dim=steps))\n",
    "model_2layer_lin.add(Dense(100, activation='linear', input_dim=100))\n",
    "model_2layer_lin.add(Dense(1))\n",
    "model_2layer_lin.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FC9726XYrZJy",
    "outputId": "f40a524c-fb18-411b-abcf-2a6fdeb55d93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8878233860>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2layer_sig.fit(X_train, y_train, epochs=5, batch_size = 64, verbose=0)\n",
    "model_2layer_tanh.fit(X_train, y_train, epochs=5, batch_size = 64, verbose=0)\n",
    "model_2layer_lin.fit(X_train, y_train, epochs=5, batch_size = 64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "lTaAUGSiqes9",
    "outputId": "8c51bc36-6ee2-4de6-e773-b2c502a971c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with sigmoid activation: 0.07\n",
      "Variance score with sigmoid activation: 0.94\n",
      "Mean squared error with tanh activation: 0.07\n",
      "Variance score with tanh activation: 0.94\n",
      "Mean squared error with linear activation: 0.07\n",
      "Variance score with linear activation: 0.94\n"
     ]
    }
   ],
   "source": [
    "y_pred_2layer_sig = model_2layer_sig.predict(X_test, verbose=0)\n",
    "y_pred_2layer_tanh = model_2layer_tanh.predict(X_test, verbose=0)\n",
    "y_pred_2layer_lin = model_2layer_lin.predict(X_test, verbose=0)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "print(\"Mean squared error with sigmoid activation: %.2f\" % mean_squared_error(y_test, y_pred_2layer_tanh))\n",
    "print('Variance score with sigmoid activation: %.2f' % r2_score(y_test, y_pred_2layer_tanh))\n",
    "\n",
    "print(\"Mean squared error with tanh activation: %.2f\" % mean_squared_error(y_test, y_pred_2layer_tanh))\n",
    "print('Variance score with tanh activation: %.2f' % r2_score(y_test, y_pred_2layer_tanh))\n",
    "\n",
    "print(\"Mean squared error with linear activation: %.2f\" % mean_squared_error(y_test, y_pred_2layer_lin))\n",
    "print('Variance score with linear activation: %.2f' % r2_score(y_test, y_pred_2layer_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HW5yPqLksQnF"
   },
   "source": [
    "### Taking observation window of more than an hour\n",
    "\n",
    "\n",
    "\n",
    ">   Observation window of two hours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "d4pWqCDUsujO",
    "outputId": "9e639710-3af7-45de-915d-9a4f408fcfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input-output samples : (2075139, 120)\n",
      "Mean squared error with two-hour window: 0.07\n",
      "Variance score with two-hour window: 0.94\n"
     ]
    }
   ],
   "source": [
    "##### Observation window of two hours #####\n",
    "steps = 120\n",
    "X, y = split_sequence(df.to_numpy(), n_steps=steps)\n",
    "print(\"Number of input-output samples :\",np.shape(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 42)\n",
    "\n",
    "##### Model with two hidden layers #####\n",
    "model_2layer = Sequential()\n",
    "model_2layer.add(Dense(100, activation='relu', input_dim=steps))\n",
    "model_2layer.add(Dense(100, activation='relu', input_dim=100))\n",
    "model_2layer.add(Dense(1))\n",
    "model_2layer.compile(optimizer='adam', loss='mse')\n",
    "model_2layer.fit(X_train, y_train, epochs=5, batch_size = 64, verbose=0)\n",
    "\n",
    "y_pred_2layer = model_2layer.predict(X_test, verbose=0)\n",
    "\n",
    "print(\"Mean squared error with two-hour window: %.2f\" % mean_squared_error(y_test, y_pred_2layer))\n",
    "print('Variance score with two-hour window: %.2f' % r2_score(y_test, y_pred_2layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8VcQZ2Vtjq_"
   },
   "source": [
    "> Observation window of three hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "5CSA5qZPtwht",
    "outputId": "dee9a8f6-f0f0-4b9d-c555-dacd05e43d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input-output samples : (2075079, 180)\n",
      "Mean squared error with three-hour window: 0.07\n",
      "Variance score with three-hour window: 0.94\n"
     ]
    }
   ],
   "source": [
    "##### Observation window of three hours #####\n",
    "steps = 180\n",
    "X, y = split_sequence(df.to_numpy(), n_steps=steps)\n",
    "print(\"Number of input-output samples :\",np.shape(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state = 42)\n",
    "\n",
    "##### Model with two hidden layers #####\n",
    "model_2layer = Sequential()\n",
    "model_2layer.add(Dense(100, activation='relu', input_dim=steps))\n",
    "model_2layer.add(Dense(100, activation='relu', input_dim=100))\n",
    "model_2layer.add(Dense(1))\n",
    "model_2layer.compile(optimizer='adam', loss='mse')\n",
    "model_2layer.fit(X_train, y_train, epochs=5, batch_size = 64, verbose=0)\n",
    "\n",
    "y_pred_2layer = model_2layer.predict(X_test, verbose=0)\n",
    "\n",
    "print(\"Mean squared error with three-hour window: %.2f\" % mean_squared_error(y_test, y_pred_2layer))\n",
    "print('Variance score with three-hour window: %.2f' % r2_score(y_test, y_pred_2layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiewGqmtJm-X"
   },
   "source": [
    "### Using Linear regression\n",
    "\n",
    "\n",
    "> Define the Linear regression class (using the class definition from previous assignment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kfq3vM9_U7lm"
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "    def fit(self, X, y, lr = 0.001, iters=1000, verbose=True, batch_size=1):\n",
    "        X = self.add_bias(X)\n",
    "        self.weights = np.zeros(len(X[0]))\n",
    "        for i in range(iters):\n",
    "            idx = np.random.choice(len(X), batch_size) \n",
    "            X_batch, y_batch =  X[idx], y[idx]\n",
    "            self.weights -= lr * self.get_gradient(X_batch, y_batch)\n",
    "            if i % 1000 == 0 and verbose: \n",
    "                print('Iterations: %d - Error : %.4f' %(i, self.get_loss(X,y)))\n",
    "                \n",
    "    def predict(self, X):\n",
    "        return self.predict_(self.add_bias(X))\n",
    "    \n",
    "    def get_loss(self, X, y):\n",
    "        return np.mean((y - self.predict_(X)) ** 2)\n",
    "    \n",
    "    def predict_(self, X):\n",
    "        return np.dot(X,self.weights)\n",
    "    \n",
    "    def add_bias(self,X):\n",
    "        return np.insert(X, 0, np.ones(len(X)), axis=1)\n",
    "        \n",
    "    def get_gradient(self, X, y):\n",
    "        return -1.0 * np.dot(y - self.predict_(X), X) / len(X)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        return self.get_loss(self.add_bias(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B73fjqFKJ6Pj"
   },
   "source": [
    "\n",
    "\n",
    "> Fit the train data using linear regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "UbRe_iBk0hif",
    "outputId": "c6142d07-7430-44a1-9e56-a0a5322e184d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0 - Error : 2.2557\n",
      "Iterations: 1000 - Error : 0.1640\n",
      "Iterations: 2000 - Error : 0.1170\n",
      "Iterations: 3000 - Error : 0.1924\n",
      "Iterations: 4000 - Error : 0.0932\n",
      "Iterations: 5000 - Error : 0.0953\n",
      "Iterations: 6000 - Error : 0.1168\n",
      "Iterations: 7000 - Error : 0.2455\n",
      "Iterations: 8000 - Error : 0.0850\n",
      "Iterations: 9000 - Error : 0.0799\n",
      "Iterations: 10000 - Error : 0.0863\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train, iters = 11000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rI8REeXpKAOl"
   },
   "source": [
    "\n",
    "\n",
    "> Calculate the MSE and R2-score for the linear regression model.\n",
    "\n",
    "> Observation : The model seems to converge with 10K- 11K iteratons.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jeviY1RF9FK1",
    "outputId": "b09c655a-a903-49b4-8f6d-e091583f2532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.11\n",
      "Variance score: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "smai_a3_q4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
